<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Hexo</title><meta name="author" content="John Doe"><meta name="copyright" content="John Doe"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="https://niiickz.github.io/page/2/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://niiickz.github.io/page/2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hexo',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2023-12-02 21:43:36'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">92</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">1</div></a></div><hr class="custom-hr"/></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Hexo"><span class="site-name">Hexo</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Hexo</h1></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/09/06/Spectral-based%20ConvGNN%E5%9F%BA%E7%A1%80/" title="Spectral-based ConvGNN基础">Spectral-based ConvGNN基础</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-09-06T08:29:55.000Z" title="Created 2023-09-06 16:29:55">2023-09-06</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">相关论文链接：
GNN综述：A Comprehensive Survey on Graph Neural Networks
初代Spectral-based ConvGNN：Spectral Networks and Deep Locally Connected Networks on Graphs
无向图的拉普拉斯矩阵拉普拉斯算子拉普拉斯算子定义为空间标量函数梯度的散度，设有多元函数$f(x_1,…,x_n)$，则其拉普拉斯算子定义为

\nabla^2 f=\sum_{i=1}^n\frac{\partial^2 f}{\partial x_i^2}我们知道标量场在某点的梯度是一个向量，指向该点处变化率最大的方向，模为对应的最大变化率
而向量场在某点的散度是一个标量，描述该点是“正源”还是“负源”，或者说散度是通量的体密度
因此简单来说，拉普拉斯算子描述了标量函数 $f$ 在每一点处的“源”特性
例如对空间温度函数$T(x,y,z)$，拉普拉斯算子$\nabla^2 T$就描述了空间每一点倾向于吸热还是散热
离散函数的拉普拉斯算子离散函数的导数可以通过泰勒展开来近似

f(x+\D ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/09/04/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0(4)-%20Policy%20Gradient%20and%20Actor-Critic/" title="强化学习(4)- Policy Gradient and Actor-Critic">强化学习(4)- Policy Gradient and Actor-Critic</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-09-04T08:05:11.000Z" title="Created 2023-09-04 16:05:11">2023-09-04</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">Policy Gradientpolicy-based RL的目标是直接使用一个参数化函数$\pi(a|s,\theta)$对最优策略$\pi^*$进行近似
这个目标可以视为一个优化问题，假设$J(\theta)$是某个特定metric，最优策略可通过梯度法逼近

\theta \leftarrow \theta +\alpha \nabla_{\theta}J(\theta)这种方法称为策略梯度(Policy Gradient)方法
我们知道state-value $v_{\pi}(s)$衡量了在策略$\pi$控制下处于状态$s$有多好，于是期望state-value就衡量了策略$\pi$有多好

\overline{v_{\pi}}=\sum_{s\in S}d(s)v_{\pi}(s)=E_{s\sim d}[v_{\pi}(s)]其中状态$s$的分布$d(s)$有两种情况

$d(s)$与策略$\pi$独立。这种情况可以假设均匀分布$d(s)=\frac{1}{|S|}$，或者只关心初始状态$d(s_0)=1,d(s\neq s_0)=0$
$d(s)$依赖于策略$\pi$。这 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/09/04/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0(3)-%20TD%20learning/" title="强化学习(3)- TD learning">强化学习(3)- TD learning</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-09-04T08:04:26.000Z" title="Created 2023-09-04 16:04:26">2023-09-04</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">TD Learning是Value-based RL最常用的算法
Value-based RL的目标是学习最优Q函数$Q^*(s,a)$
然后选择使得Q值最大的动作$a_t=\arg\max_a Q^*(s_t,a)$作为最优策略
我们首先介绍TD Learning的思想，然后介绍几个重要的TD方法——SARSA、Q-learning和DQN
Temporal Difference Learning时序差分学习(TD Learning)指的是一类算法，其通过自举(bootstrapping)的方式学习value function
我们首先通过一个例子来说明其思想，假设我们需要估计开车从A地到B地的时间$V(A)$，初始估计值$V(A)=10 h$
MC方法的思路是直接完成一次从A地到B地的路程，得到实际的总路程时间$8h$
实际时间与估计值误差为$2h$，于是更新估计值$V(A)\leftarrow 10-2\alpha$，其中常数$\alpha$可视为学习率
而TD Learning的思路是，先从A地开到位于A、B中间的C地，获得其实际路程时间$2h$
设C地到B地的预测时间为$V( ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/09/04/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0(2)-%20DP%20and%20MC/" title="强化学习(2)- DP and MC">强化学习(2)- DP and MC</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-09-04T08:02:59.000Z" title="Created 2023-09-04 16:02:59">2023-09-04</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">动态规划(DP)和蒙特卡洛(MC)都是RL的早期方法，虽然早已不再使用，但它们仍是后续一系列方法的重要基础
DP和MC都属于表格方法(tabular method)，因为其假设MDP的状态空间和动作空间均离散且非常小，从而value function的取值可以用一个表格表示
与之相对的，近似方法(approximation method)用于解决状态/动作空间连续或非常大的情况，其使用一个参数化函数$f(s,a,\theta)$来近似value function
DPDP方法是一类model-based方法，即MDP的状态转移概率已知
这里介绍两个DP方法——策略迭代 (Policy Iteration) 和值迭代 (Value Iteration)
策略迭代方法迭代地进行如下两步以使策略收敛至最优

策略评估 (Policy Evaluation) ：对于当前策略$\pi$，计算所有状态对应的state-value $V_{\pi}(s)$
策略提升 (Policy Improvement) ：利用策略评估得到的$V_{\pi}(s)$为每个状态寻找更优的策略

值迭代方法直接迭代得 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/09/04/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0(1)-%20%E5%9F%BA%E7%A1%80/" title="强化学习(1)- 基础">强化学习(1)- 基础</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-09-04T08:02:17.000Z" title="Created 2023-09-04 16:02:17">2023-09-04</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">基本概念和术语强化学习 (Reinforcement Learning, RL) 是一种基于行为主义的机器学习方法，其本质是通过交互进行试错学习
RL使用一个由算法控制的智能体agent与环境environment进行互动，互动过程包含下面这些概念：

state：状态$s_t$表示timestep $t$ 时的完整环境信息
observation：观测$o$表示状态$s$对agent可见的部分（大多数文献都将两者视为同一概念，并直接用$s$表示）
action：动作$a_t$是agent观察到状态$s_t$后采取的行动，所有可能的动作集合称为动作空间
policy：策略控制agent在状态$s_t$下如何选择动作$a_t$，策略可能是确定性的，即$a_t=\pi(s_t)$；或随机性的，即$a_t\sim \pi(a|s_t)$
reward：奖励$r{t+1}$是采取动作$a_t$后产生的反馈，可表示为$r{t+1}=R(at,s_t,s{t+1})$，这是RL进行学习的依据
trajectory：轨迹$\tau=(s_0,a_0,s_1,a_1\cdots)$表示agent与环境 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/08/05/Memory%20Networks/" title="Memory Networks">Memory Networks</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-08-05T08:49:56.000Z" title="Created 2023-08-05 16:49:56">2023-08-05</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">Memory NetworksWeston J, Chopra S, Bordes A. Memory networks[J]. arXiv preprint arXiv:1410.3916, 2014.
传统的机器学习模型都没有记忆模块，像RNN这样的模型虽然有一定的记忆能力，但是长期记忆能力仍然很弱
Memory networks首次提出了具有记忆模块的模型
该模型的记忆模块$m$类似于计算机内存，是一个由$m_i$索引的数组
模型由$I,G,O,R$四个部分组成：

I：input feature map，将输入转换为内部特征表示，记为$I(x)$
G：generalization，根据新的输入更新$m$，即$m_i=G(m_i,I(x),m)$
O：output feature map，根据$m$和当前输入产生输出的特征表示$o=O(I(x),m)$
R：response，将output feature转换为期望的输出形式$r=R(o)$

显然这样的模型难以端到端训练
End-to-End Memory networksSukhbaatar S, Weston J, Ferg ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/08/03/A%20Simple%20Review%20of%20Spatial-based%20ConvGNN/" title="A Simple Review of Spatial-based ConvGNN">A Simple Review of Spatial-based ConvGNN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-08-03T14:34:52.000Z" title="Created 2023-08-03 22:34:52">2023-08-03</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">相关文章：Spatial-based ConvGNN基础
DCNN论文：[1] Diffusion-convolutional neural networks [2] Diffusion convolutional recurrent neural network Data-driven traffic forecasting
DCNN (Diffusion CNN) 最早由[1]提出
DCNN假设图信号在节点间的转移是一个扩散过程
令$P=D^{-1}A$为归一化转移概率矩阵，$P_{ij}$表示任意时刻信息从节点$i$转移到节点$j$的概率
容易看出矩阵$P$实际上就是邻接矩阵$A$的行归一化形式
扩散过程实际上是一个以$P$为转移概率的马尔科夫链，那么时刻$k$的节点间的扩散概率为$P^k$
于是$k$跳的图扩散卷积定义为

\mathbf{H}^{(k)}=f(\mathbf{W}^{(k)}\odot \mathbf{P}^k\mathbf{X})其中$\odot$表示元素对应相乘
容易发现$H^{(k)}$的计算没有用到上一层表示$H^{(k-1)}$，且和$X$维度相同
 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/08/03/Spatial-based%20ConvGNN%E5%9F%BA%E7%A1%80/" title="Spatial-based ConvGNN基础">Spatial-based ConvGNN基础</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-08-03T06:33:15.000Z" title="Created 2023-08-03 14:33:15">2023-08-03</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">相关论文链接：
GNN综述：A Comprehensive Survey on Graph Neural Networks
NN4G：Neural Network for Graphs: A Contextual Constructive Approach
MPNN：Neural message passing for quantum chemistry
Spatial-based ConvGNN和spectral-based不同，Spatial-based直接将图像卷积推广到了图上
CNN中卷积操作通过计算$k\times k$小区域中像素值的加权平均作为其中心点的卷积值
类似的，Spatial-based ConvGNN将中心节点及其邻居节点的特征分别处理并进行聚合（称为aggregation，例如求和、平均、加权等）后作为中心节点的卷积值

以下做一个统一的符号定义
$\mathbf{x}\in R^n,\mathbf{X}\in R^{n\times d}$分别表示原始的单通道/多通道图节点特征，$\mathbf{x}_v\in R^d$表示节点$v$的原始节点特征，$\mat ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/08/02/ChebNet%20and%20GCN/" title="ChebNet and GCN">ChebNet and GCN</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-08-02T12:42:33.000Z" title="Created 2023-08-02 20:42:33">2023-08-02</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">相关论文链接：
GNN综述：A Comprehensive Survey on Graph Neural Networks
ChebNet：Convolutional neural networks on graphs with fast localized spectral filtering
GCN：Semi-supervised classification with graph convolutional networks
Spectral-based ConvGNN一般形式为

\mathbf{x}*\mathbf{g}_{\theta}=\mathbf{U}\mathbf{g}_{\theta}\mathbf{U}^T\mathbf{x}其中$\mathbf{g}_{\theta}=diag(\mathbf{U}^T\mathbf{g})$为卷积核
ChebNetSpectral-based ConvGNN原始形式中的卷积核$\mathbf{g}_{\theta}(\Lambda)=diag(\theta_1,…,\theta_n)$存在两个问题

非局部化，即每次卷积都用 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2023/08/01/A%20Review%20of%20Recent%20Multimodal%20ERC%20model/" title="A Review of Recent Multimodal ERC model">A Review of Recent Multimodal ERC model</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2023-08-01T12:57:34.000Z" title="Created 2023-08-01 20:57:34">2023-08-01</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">这篇文章简述了21~23年的一些有代表性的Multimodal ERC (Multimodal Emotion Recognition in Conversation) 模型，它们的共同点是都基于GNN (Graph Neural Network)
为方便描述，这里先做一个统一的符号定义
一段对话由$N$个utterance ${u_1,\cdots,u_N}$组成，每个$u_i$包含听觉、视觉、文本三个模态，记为$u_i={u_i^a,u_i^v,u_i^t}$，其中$u_i^a\in R^{d_a},u_i^v\in R^{d_v},u_i^t\in R^{d_t}$分别为已提取的听觉、视觉、文本特征，每个$u_i$对应一个情感标签$y_i$
每段对话包含$M$个speaker ${p1,\cdots,p_M}$，$p{\phi(ui)}$表示$u_i$对应的speaker，$U{\lambda}$（或$U^{(\lambda)}$）表示来自$p_{\lambda}$的utterance集合
MMGCNMMGCN——Multimodal Fused Graph Convolutio ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/#content-inner">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/#content-inner">10</a><a class="extend next" rel="next" href="/page/3/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">John Doe</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">92</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/10/05/IMAGEBIND%20and%20PandaGPT%E7%AE%80%E4%BB%8B/" title="IMAGEBIND and PandaGPT简介">IMAGEBIND and PandaGPT简介</a><time datetime="2023-10-05T08:15:47.000Z" title="Created 2023-10-05 16:15:47">2023-10-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/09/30/Flamingo%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="Flamingo论文解读">Flamingo论文解读</a><time datetime="2023-09-30T12:31:31.000Z" title="Created 2023-09-30 20:31:31">2023-09-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/09/29/OSCAR%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="OSCAR论文解读">OSCAR论文解读</a><time datetime="2023-09-29T09:32:34.000Z" title="Created 2023-09-29 17:32:34">2023-09-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/09/28/FlAN%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="FlAN系列论文解读">FlAN系列论文解读</a><time datetime="2023-09-28T08:43:46.000Z" title="Created 2023-09-28 16:43:46">2023-09-28</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/09/27/NExT-GPT%20Any-to-Any%20Multimodal%20LLM/" title="NExT-GPT Any-to-Any Multimodal LLM">NExT-GPT Any-to-Any Multimodal LLM</a><time datetime="2023-09-27T02:22:53.000Z" title="Created 2023-09-27 10:22:53">2023-09-27</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>Categories</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">深度学习</span><span class="card-category-list-count">92</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/LLM/" style="font-size: 1.1em; color: #999">LLM</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span><a class="card-more-btn" href="/archives/" title="View More">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/10/"><span class="card-archive-list-date">October 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/09/"><span class="card-archive-list-date">September 2023</span><span class="card-archive-list-count">14</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/08/"><span class="card-archive-list-date">August 2023</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/07/"><span class="card-archive-list-date">July 2023</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/05/"><span class="card-archive-list-date">May 2023</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/04/"><span class="card-archive-list-date">April 2023</span><span class="card-archive-list-count">13</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/03/"><span class="card-archive-list-date">March 2023</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/02/"><span class="card-archive-list-date">February 2023</span><span class="card-archive-list-count">3</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">92</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">Last Update :</div><div class="item-count" id="last-push-date" data-lastPushDate="2023-12-02T13:43:36.051Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By John Doe</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>