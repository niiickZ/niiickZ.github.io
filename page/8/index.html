<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Hexo</title><meta name="author" content="John Doe"><meta name="copyright" content="John Doe"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="Hexo">
<meta property="og:url" content="https://niiickz.github.io/page/8/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://niiickz.github.io/page/8/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hexo',
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isToc: false,
  postUpdate: '2023-12-02 21:43:36'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">92</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">1</div></a></div><hr class="custom-hr"/></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="Hexo"><span class="site-name">Hexo</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="site-info"><h1 id="site-title">Hexo</h1></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2022/11/20/%E9%AB%98%E7%BA%A7%E5%8A%A0%E5%AF%86%E6%A0%87%E5%87%86AES/" title="高级加密标准AES">高级加密标准AES</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-11-20T06:07:19.000Z" title="Created 2022-11-20 14:07:19">2022-11-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">鉴于DES可以被破解和加密效率不高的缺陷，NIST于1997年开始公开征集新的高级加密标准AES选拔标准是分组长度为128位的分组密码、支持128/192/256三种长度的密钥、软硬件效率高2000年Rijmen提出的Rijndael算法被NIST选为高级加密标准AES，并于2001年正式发布
AES的基础是有限域$GF(2^8)$上的运算，其中选择的素多项式是$m(x)=x^8+x^4+x^3+x+1$有关有限域的基本概念可以参考 密码学的近世代数基础
AES总体结构如图所示AES共有N轮迭代，除最后一轮迭代外，每一轮迭代包含字节代替、行位移、列混淆和轮密钥加4个部分，而最后一轮则不包含列混淆，此外第1轮迭代前有一次轮密钥加
密钥经过密钥扩展算法后，按顺序每4个字（16字节）作为一次迭代的密钥
AES的迭代轮数N是于密钥长度相关的，若密钥为128位（4个字），则扩展为44字，对应10轮；若密钥为192位则对应12轮；若为256位则对应14轮

此外加密过程中消息和密钥是矩阵形式，明文/密钥的16字节将按列存储到一个4×4矩阵中，上述轮密钥加就是用消息矩阵和密钥矩阵按对应位置直接异或
 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2022/11/18/%E5%AF%86%E7%A0%81%E5%AD%A6%E7%9A%84%E8%BF%91%E4%B8%96%E4%BB%A3%E6%95%B0%E5%9F%BA%E7%A1%80/" title="密码学的近世代数基础">密码学的近世代数基础</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-11-18T07:49:15.000Z" title="Created 2022-11-18 15:49:15">2022-11-18</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">近世代数作为理论数学的一个完整分支，其对群、环、域等的研究非常复杂，此处仅总结一些与密码学相关的概念和基础
群首先定义代数运算

定义集合M上的一个法则 $\cdot$ ，若对于M上的每一组有序对$(a,b)$，$a,b\in M$，总存在唯一的$d\in M$使得$a\cdot b=d$成立，即满足封闭性，则法则 $\cdot$ 被称为M上的一个代数运算

设G是一个定义了代数运算 $\cdot$ 的非空集合，当满足如下条件时称G对代数运算 $\cdot$ 做成一个群

结合律：若$a,b,c\in G$，则$a\cdot(b\cdot c)=(a\cdot b)\cdot c$
存在左单位元：存在一个元素$e\in G$，使得对G中任意元素$a$，都有$e\cdot a=a$成立
存在左逆元：对G中任意元素$a$，在G中都有元素$a^{-1}$，使得$a^{-1}\cdot a=e$

群有一些重要定理

群G的左单位元也是右单位元，即有$e\cdot a=a\cdot e=a$，且单位元是唯一的
群G中任意元素$a$的左逆元$a^{-1}$也是其右逆元，即有$a\cdot a^  ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2022/11/16/%E5%8F%A4%E5%85%B8%E5%8A%A0%E5%AF%86%E6%A6%82%E8%BF%B0/" title="古典加密概述">古典加密概述</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-11-16T07:29:40.000Z" title="Created 2022-11-16 15:29:40">2022-11-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">替代密码Caesar密码Caesar密码是最早的替代密码，其方法很简单，即对每个字母用字母表中它之后第3个字母代替它
其加密、解密的一般形式分别为 $C=E(k,p)=(p+k)\mod 26$ 和 $p=D(k,C)=(C-k)\mod 26$
其中k表示字母在字母表中位移的位数
单表代替密码单表代替密码即建立大小相同的明文字符集合到密文字符集合的一一映射，Caesar密码就是一种特殊的单表代替密码
显然具有$n$个元素的字符集合可以定义出$n!$种不同的加密
单表代替密码可以抵御穷举攻击，但却可以被统计频率攻击轻松攻破
假设我们已知明文语言为英语，那么我们可以统计出如图所示的字母出现频率假设截获的密文长度足够，则可根据其字符频率很容易的分析出明文

Playfair密码应对单表代替密码统计频率攻击的一种方法是对明文中多个字母一起加密
Playfair算法基于密钥词构造一个5×5的字母矩阵，构造方法为按从左到右、从上到下的顺序，先填充密钥词，再按顺序填充其他字母，其中I、J视为同一个字母
以密钥词monarchy为例，构造的矩阵如下




M
O
N
A
R




C
H
Y
B ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2022/08/07/Perceptual%20Loss/" title="Perceptual Loss">Perceptual Loss</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-08-07T04:39:58.000Z" title="Created 2022-08-07 12:39:58">2022-08-07</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">论文链接：Perceptual Losses for Real-Time Style Transfer and Super-Resolution
Perceptual Loss的提出对于众多Image Transfermation任务来说，最典型的方法就是使用per-pixel loss训练一个前馈网络
这种方法有一个明显缺点，就是无法捕获感知差异（Perceptual Differences）
例如两张仅偏移1个像素的图片，感知上他们是相同的，但per-pixel loss却可能很大
而Gatys等人在论文 A neural algorithm of artistic style 中提出了另一种方法，即使用从预训练卷积神经网络中提取的高级图像特征之间的差异作为Perceptual Loss
该方法可以生成十分高质量的图像，然而其网络的inference非常慢，因为网络参数的optimization是与inference一同进行的
基于上述工作，改论文的作者提出了Perceptual Loss的预训练前馈网络版本，以实现inference阶段实时生成高质量图像
Perceptual L ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2022/03/02/%E7%A5%9E%E7%BB%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/" title="神经风格迁移">神经风格迁移</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-03-02T13:04:34.000Z" title="Created 2022-03-02 21:04:34">2022-03-02</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">什么是神经风格迁移图像风格迁移一直是cv领域的一个难题传统图像处理中有很多针对该问题的非参数化算法，这些算法的局限都在于只能提取图像的低层特征
2015年Gatys等人提出了基于神经网络的图像风格迁移算法，即神经风格迁移神经风格迁移使用预训练的深度CNN提取图像高层特征，独立构造出了图像的内容/风格表示该算法表现十分优异，使得图像风格迁移在神经网络研究中流行起来
论文链接：
A neural algorithm of artistic style
Image Style Transfer Using Convolutional Neural Networks
自己训练的模型效果如下

内容与风格的提取深度内容表达以VGG为例，为了将深度CNN模型每一层学得的特征可视化我么可以将一张随机噪声图和一张正常照片同时输入网络，计算网络第l层输出的两张特征图之间的loss，再对噪声图进行梯度下降
即设$\vec{p},\vec{x}$分别为输入的原图和噪声图，$P^l,F^l$分别为他们在网络第$l$层的输出特征图，其尺寸为$(H_l,W_l,C_l)$，则有square-error

\mat ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2022/02/20/SpeechTransformer/" title="SpeechTransformer">SpeechTransformer</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-02-20T13:37:43.000Z" title="Created 2022-02-20 21:37:43">2022-02-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">论文链接：Speech-Transformer——A No-Recurrence Sequence-to-Sequence Model for Speech Recognition
Speech Transformer即应用于语音识别的Transformer如下图所示其结构与普通Transformer结构基本完全一致不了解Transformer的可以看这篇博客Transformer——Attention is all you need详解，此处不再赘述

Speech Transformer的亮点在于encoder中的2D Multi-Head Attention因为语音识别的输入一般是2D频谱图，若用普通的attention则只能提取时间方向的特征
如图所示，因为是self-attention层，所以其输入只有一个，是尺寸为(height, width, channels)的特征图首先对输入应用三个不同的卷积得到Query、Key和Value再对Q,K,V分别进行filter数为c的卷积，c即表示head数，记为Q’,K’,V’
对Q’,K’,V’的c个通道分别进行Scaled Do ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2022/02/20/seq2seq%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E2%80%94%E2%80%94LAS/" title="seq2seq语音识别——LAS">seq2seq语音识别——LAS</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-02-20T11:49:32.000Z" title="Created 2022-02-20 19:49:32">2022-02-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">LAS的提出语音识别的研究中端到端的模型正在逐渐取代将声学（acoustic）、发音（pronunciation）和语言（language）模型分别单独训练的方法
端到端的模型主要有两中，一种是CTC，另一种是带有Attention机制的seq2seqCTC的局限在于其假设输出label是相互条件独立的，而seq2seq则还没有端到端的语音识别
LAS（Attend Listen and Spell）是首个将带Attention的seq2seq应用于端到端的语音识别模型
论文链接：Listen, Attend and Spell
模型结构LAS中的Encoder称为Listener，Decoder称为Speller，其结构如图所示
Listener是金字塔型双向LSTM（pyramid BLSTM）每一层通过将相邻timestep输出concat成一个向量使序列长度减半（个人认为也可以通过1D池化达到相同效果）
金字塔型LSTM的作用是减少Attention的计算量，加速收敛
Speller与普通的带Attention的seq2seq Decoder完全一样

这里贴一下金字塔型RNN ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2022/02/20/DeepSpeech2%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="DeepSpeech2论文解读">DeepSpeech2论文解读</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-02-20T09:21:56.000Z" title="Created 2022-02-20 17:21:56">2022-02-20</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">DeepSpeech2是由Baidu AI LaB于2015年发布的语音识别模型DeepSpeech2和初版DeepSpeech一样是端到端的模型，新论文相较于初版改进主要有

修改了模型，引入卷积层和BatchNorm，以及新设计的Lookahead Convolution
增加了对中文语音识别的讨论
基于HPC的多GPU训练加速

论文链接：
DeepSpeech—— Deep Speech - Scaling up end-to-end speech recognitionDeepSpeech2—— Deep Speech 2 - End-to-End Speech Recognition in English and Mandarin
模型结构DeepSpeech2结构如下图所示

模型输入是频谱图（spectrogram），接下来先是多层1D或2D卷积层，论文实验结果表明1D卷积的效果不大，2D卷积在noisy data上效果明显，但在clean data上效果不大
然后是多个（双向）RNN层，论文实验表明在Batchnorm的帮助下普通RNN（Vanilla RNN）效果也 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2022/02/19/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BGPT/" title="预训练语言模型GPT">预训练语言模型GPT</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-02-19T13:53:34.000Z" title="Created 2022-02-19 21:53:34">2022-02-19</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">论文链接：GPT： Improving Language Understanding by Generative Pre-TrainingGPT-2：Language Models are Unsupervised Multitask LearnersGPT-3：Language Models are Few-Shot Learners
GPT-2和GPT-3都主要是增大了模型规模，下面讲解的是原GPT论文GPT实现只需要稍微修改Transformer的代码，下面不贴代码了，可以到我的GitHub看GPT.py

GPT是第一个取得显著成功的学习高层次语义特征的预训练语言模型此前的预训练语言模型一般都是单词级的，即预训练词嵌入，再设计任务特定的网络结构而GPT在预训练之后则只用引入较少参数来适应特定任务（往往只有一个全连接分类层）
此外以往的预训练模型往往采用RNN，使得预测范围很小而GPT选择使用Transformer Decoder结构避免了这种问题

GPT是多个Transformer Block堆叠的结构，每个Block的Attention层使用了Future Mask，但是没 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2022/02/19/%E5%8F%8C%E5%90%91%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8BBERT%E8%AF%A6%E8%A7%A3/" title="双向预训练语言模型BERT详解">双向预训练语言模型BERT详解</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2022-02-19T11:42:50.000Z" title="Created 2022-02-19 19:42:50">2022-02-19</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="content">BERT的提出在之前的研究中，预训练语言模型已被证明对各类NLP问题都十分有效然而BERT作者认为已有的技术仍然限制了预训练的效果，因为他们都是单向的
例如GPT，使用了Transformer Decoder，其中的future mask使得它只能单向，且预训练任务也只是简单的句子生成以及ELMo，只是简单的将独立训练的left-to-right和right-to-left模型拼接在一起
因此作者提出了BERT（Bidirectional Encoder Representations from Transformers）利用Transformer Encoder以及MLM和NSP任务实现在于训练中学得双向的语言表达
论文链接：BERT: Pre-training of Deep Bidirectional Transformers for Language UnderstandingBERT MLM任务的简单实现 BERT_MLM.py
BERT结构bert结构十分简单，就是多个Transformer Encoder块的堆叠如果输入是句子对(A, B)，那么将两个句子拼接在一起并用特 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/7/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/#content-inner">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/#content-inner">9</a><a class="page-number" href="/page/10/#content-inner">10</a><a class="extend next" rel="next" href="/page/9/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">John Doe</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">92</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">1</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">1</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/10/05/IMAGEBIND%20and%20PandaGPT%E7%AE%80%E4%BB%8B/" title="IMAGEBIND and PandaGPT简介">IMAGEBIND and PandaGPT简介</a><time datetime="2023-10-05T08:15:47.000Z" title="Created 2023-10-05 16:15:47">2023-10-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/09/30/Flamingo%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="Flamingo论文解读">Flamingo论文解读</a><time datetime="2023-09-30T12:31:31.000Z" title="Created 2023-09-30 20:31:31">2023-09-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/09/29/OSCAR%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="OSCAR论文解读">OSCAR论文解读</a><time datetime="2023-09-29T09:32:34.000Z" title="Created 2023-09-29 17:32:34">2023-09-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/09/28/FlAN%E7%B3%BB%E5%88%97%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/" title="FlAN系列论文解读">FlAN系列论文解读</a><time datetime="2023-09-28T08:43:46.000Z" title="Created 2023-09-28 16:43:46">2023-09-28</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/09/27/NExT-GPT%20Any-to-Any%20Multimodal%20LLM/" title="NExT-GPT Any-to-Any Multimodal LLM">NExT-GPT Any-to-Any Multimodal LLM</a><time datetime="2023-09-27T02:22:53.000Z" title="Created 2023-09-27 10:22:53">2023-09-27</time></div></div></div></div><div class="card-widget card-categories"><div class="item-headline">
            <i class="fas fa-folder-open"></i>
            <span>Categories</span>
            
            </div>
            <ul class="card-category-list" id="aside-cat-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">深度学习</span><span class="card-category-list-count">92</span></a></li>
            </ul></div><div class="card-widget card-tags"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/LLM/" style="font-size: 1.1em; color: #999">LLM</a></div></div><div class="card-widget card-archives"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span><a class="card-more-btn" href="/archives/" title="View More">
    <i class="fas fa-angle-right"></i></a></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/10/"><span class="card-archive-list-date">October 2023</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/09/"><span class="card-archive-list-date">September 2023</span><span class="card-archive-list-count">14</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/08/"><span class="card-archive-list-date">August 2023</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/07/"><span class="card-archive-list-date">July 2023</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/05/"><span class="card-archive-list-date">May 2023</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/04/"><span class="card-archive-list-date">April 2023</span><span class="card-archive-list-count">13</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/03/"><span class="card-archive-list-date">March 2023</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2023/02/"><span class="card-archive-list-date">February 2023</span><span class="card-archive-list-count">3</span></a></li></ul></div><div class="card-widget card-webinfo"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="item-name">Article :</div><div class="item-count">92</div></div><div class="webinfo-item"><div class="item-name">UV :</div><div class="item-count" id="busuanzi_value_site_uv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">PV :</div><div class="item-count" id="busuanzi_value_site_pv"><i class="fa-solid fa-spinner fa-spin"></i></div></div><div class="webinfo-item"><div class="item-name">Last Update :</div><div class="item-count" id="last-push-date" data-lastPushDate="2023-12-02T13:43:36.051Z"><i class="fa-solid fa-spinner fa-spin"></i></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By John Doe</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>